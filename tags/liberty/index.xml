<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>liberty on ebullient·works</title><link>/tags/liberty.html</link><description>Recent content in liberty on ebullient·works</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 27 Nov 2017 00:00:00 +0000</lastBuildDate><atom:link href="/tags/liberty/index.xml" rel="self" type="application/rss+xml"/><item><title>airhacks.fm: Java EE ebullience — podcast with Adam Bien</title><link>/2017/11/27/airhacks-fm.html</link><pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate><guid>/2017/11/27/airhacks-fm.html</guid><description>&lt;p>I spent an excellent few hours recording a podcast with Adam Bien.&lt;/p>
&lt;p>CORBA? OpenLiberty? Robots? The glory days of object marshaling? Such a trip down memory lane! We could easily have talked for another hour.&lt;/p>
&lt;p>Can you hear my rings clinking on my favorite mug? Yes, yes you can.&lt;/p>
&lt;p>Give it a listen:&lt;/p>
&lt;div class="embed-container">
&lt;iframe allow="autoplay" width="100%" height="200" src="https://www.iheart.com/podcast/256-airhacksfm-podcast-with-ad-43073886/episode/java-ee-ebullience-44463279/?embed=true" frameborder="0">&lt;/iframe>
&lt;/div></description></item><item><title>IBM InterConnect 2017: Microservices, Twelve Factors, Security</title><link>/2017/03/28/ibm-interconnect-microservices-12-factors-security.html</link><pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate><guid>/2017/03/28/ibm-interconnect-microservices-12-factors-security.html</guid><description>&lt;p>Lots to talk about this year. So many sessions.&lt;/p>
&lt;ol>
&lt;li>Best practices for creating secure microservices&lt;/li>
&lt;li>Creating Twelve Factor Applications with Liberty on Bluemix: a Practical Guide&lt;/li>
&lt;li>Monolithic Application to Microservice Architecture: How to break down your existing Application&lt;/li>
&lt;li>Real-World Microservice Development with IBM WebSphere Liberty: Game On!&lt;/li>
&lt;/ol>
&lt;p>There were a few more that I haven&amp;rsquo;t posted the charts for.. phew!&lt;/p></description></item><item><title>SouJava: MicroProfile at IBM</title><link>/2017/02/02/soujava-microprofile-at-ibm.html</link><pubDate>Thu, 02 Feb 2017 00:00:00 +0000</pubDate><guid>/2017/02/02/soujava-microprofile-at-ibm.html</guid><description>&lt;p>What a hoot!&lt;/p>
&lt;p>While talking about MicroProfile at IBM, Alasdair and I also got some time to reflect on how Liberty was built and how it has grown&amp;hellip;&lt;/p>
&lt;div class="embed video-player">
&lt;iframe name="nGla6-g76M0" class="youtube-player" frameborder="0" allowfullscreen
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
src="https://www.youtube.com/embed/nGla6-g76M0">
&lt;/iframe>
&lt;/div></description></item><item><title>Game On! Explore microservices with a text-based adventure</title><link>/2016/05/16/game-on-explore-microservices-with-a-text-based-adventure.html</link><pubDate>Mon, 16 May 2016 00:00:00 +0000</pubDate><guid>/2016/05/16/game-on-explore-microservices-with-a-text-based-adventure.html</guid><description>Microservices: the buzz is everywhere. Given the breadth of technologies related to the term, it can be difficult to get a full picture of what a microservices architecture should look like, or to understand why it is said that microservices architectures both remove and introduce complexity at the same time. Game On! Text Adventure is a throwback text-based adventure built to help you explore microservices concepts.
There are lots of examples of microservices that go something like: type in this code, run this build, push this button, and then poof! you have your service! Others show how to install and configure a multi-process component like etcd or consul. They even sometimes describe how to then add a service to it, and maybe even sometimes how to find the added service. But, in a lot of ways, it all seems out of context. From those examples, I only got a glimpse of one piece at a time. I never got an understanding of how an application built using a collection of interacting microservices really worked.
The premise of Game On! is simple: we provide some core elements and then you create services (one or many) to extend the world. It provides a choose-your-own-adventure approach to learning about microservices. We have walk-throughs that do what many other examples do: follow some steps, push some buttons, and TA-DA! you have a working single service written in Java, JavaScript, or Go.
A difference, however, is that your shiny new service is registered as a part of a larger system right out of the gate. The APIs that your service implements will be called by elements of the long-running composed application. How you choose to play with the next steps (making the service resilient, load-balancing and scaling, dealing with eventual consistency) becomes something that can be explored without having to implement a whole bunch of pieces yourself.
More walk-throughs will be coming over time, with most building on the basic walk-throughs we have now.All of the source is available on GitHub. We hope you enjoy working with it as much as we enjoyed building it.</description></item><item><title>IBM InterConnect 2016: Microservices, Monoliths, and Async EE7</title><link>/2016/02/26/ibm-interconnect-monoliths-microservices-ee7.html</link><pubDate>Fri, 26 Feb 2016 00:00:00 +0000</pubDate><guid>/2016/02/26/ibm-interconnect-monoliths-microservices-ee7.html</guid><description>&lt;p>Lots to talk about this year!&lt;/p>
&lt;ol>
&lt;li>Creating Twelve Factor Applications with Liberty on Bluemix&lt;/li>
&lt;li>Don&amp;rsquo;t Wait! Develop responsive applications with Java EE7 instead!&lt;/li>
&lt;li>Evolving a monolithic Java EE application to microservices: Microservices meet legacy applications&lt;/li>
&lt;/ol>
&lt;p>There were a few more that I haven&amp;rsquo;t posted the charts for..&lt;/p></description></item><item><title>Swagger-first API design</title><link>/2016/01/27/swagger-first-api-design.html</link><pubDate>Wed, 27 Jan 2016 00:00:00 +0000</pubDate><guid>/2016/01/27/swagger-first-api-design.html</guid><description>&lt;p>I've been working for the past few months on building Game On! a microservices-based application that is intended to show both what a microservices architecture looks like, and to make it easy for people to play with such a system without having to start from the ground up themselves.&lt;/p>
&lt;p>We started with a best-guess set of services, and over time, it became pretty apparent that our first pass at a map building service (the Concierge) was both misleading in purpose and insufficient in function. It did serve its purpose, filling in for service discovery in a way, but we were growing beyond what the service could do. &lt;/p></description></item><item><title>Secure Microservices: API Keys, Access Tokens, and Signed JWTs</title><link>/2015/12/04/secure-microservices-api-keys-access-tokens-and-signed-jwts.html</link><pubDate>Fri, 04 Dec 2015 00:00:00 +0000</pubDate><guid>/2015/12/04/secure-microservices-api-keys-access-tokens-and-signed-jwts.html</guid><description>Note: Originally posted on IBM developerWorks. Some of this content is old, but the gist is still useful.
I believe these two things are true:
it is very important to secure your microservices it can be difficult to read documentation trying to explain how to secure your microservices We’ve built three samples for you, which we hope will be easy to read, and will teach you something new.
Using API keys to secure your microservice is Adam’s sample. He explains what API keys are, where they come from, and how they’re used. The sample code is available on github.
Using access tokens to secure microservices is the first of two from Ozzy. He explains how the access tokens created as a result of working with OAuth and OpenID Connect work and are used within a microservices architecture.
Using signed JSON Web Tokens (JWTs) to secure microservices builds on the previous article to explain how to use Signed JWTs to propagate identity instead of access tokens.
Go play!</description></item><item><title>Using Grok filters to parse Liberty Logs</title><link>/2015/09/02/logstash-and-liberty-optimizing-data-collection-for-the-cloud.html</link><pubDate>Wed, 02 Sep 2015 00:00:00 +0000</pubDate><guid>/2015/09/02/logstash-and-liberty-optimizing-data-collection-for-the-cloud.html</guid><description>Note: Originally posted on IBM DeveloperWorks. Some of this content is old, but the gist is still useful.
Microservice architectures are highly distributed, with services provided by individual processes that are scaled independently. Understanding and maintaining overall system health becomes increasingly difficult as the system grows; it becomes impractical to look at services instance-by-instance. Monitoring systems like nagios help, but what happens when things go wrong? It is not always possible (much less easy) to ssh into any given system. In some environments the filesystem used by any given instance is transient; when the process stops, the filesystem is cleaned up, including all the logs!
The ELK stack (Elasticsearch, Logstash, and Kibana) is a commonly used system for gathering data (both logs and metrics), and allowing that data to be aggregated, analyzed, visualized, and searched in useful ways.
In this post, I&amp;rsquo;ll focus on getting the most out of WAS Liberty logs using logstash. This isn&amp;rsquo;t the only way: the IBM WebSphere Liberty buildpack in Bluemix, for example, uses loggregator (Cloud Foundry) rather than logstash. But I do hope that this gives you some ideas for how to make the logging capabilities in WAS Liberty work for your environment.
Getting useful information to system streams When operating on its own, WAS Liberty produces a few different log files by default:
&amp;ldquo;console&amp;rdquo; output is lightly formatted and contains no timestamps. Failure/error messages and System.err are routed to STDERR, while other important messages and System.out, are routed to STDOUT. When run in the background via server start, both streams are collected into a console.log file. messages.log also collects System out, System err, as well as a larger subset of messages (including INFO). trace.log only appears if detailed trace is enabled. It includes output from all enabled log sources, including System.out and System.err. Having log messages go directly to STDOUT and/or STDERR is a good environment-agnostic practice for microservices (and is also one of the 12-factors). It is a pretty simple change to get formatted Liberty logs writing to STDOUT. To ensure we don&amp;rsquo;t miss any messages from server bootstrap and startup, we&amp;rsquo;ll do this via a bootstrap.properties file that contains:
# Write WLP logs to stdout directly com.ibm.ws.logging.trace.file.name=stdout As you might infer, this re-routes what would go to trace.log to STDOUT. Before this change, STDOUT when running Liberty looks something like this:
1$ wlp/bin/server run 2Launching defaultServer (WebSphere Application Server 8.5.5.6/wlp-1.0.9.cl50620150610-1749) on Java HotSpot(TM) 64-Bit Server VM, version 1.7.0_72-b14 (en_US) 3[AUDIT ] CWWKE0001I: The server defaultServer has been launched. Afterwards, it looks more like (notice the leading timestamp and fixed fields):
1$ wlp/bin/server run 2Launching defaultServer (WebSphere Application Server 8.5.5.6/wlp-1.0.9.cl50620150610-1749) on Java HotSpot(TM) 64-Bit Server VM, version 1.7.0_72-b14 (en_US) 3[8/25/15 12:40:44:479 EDT] 00000001 id= com.ibm.ws.kernel.launch.internal.FrameworkManager A CWWKE0001I: The server defaultServer has been launched. In some cases, this might be enough. If you&amp;rsquo;re running Liberty in the foreground in a Docker container, Liberty&amp;rsquo;s formatted log entries would now be spilling out as the Docker container&amp;rsquo;s STDOUT. If the hosting environment does post-processing on that output, you may have nothing left to do.
Using logstash to post-process logs However, we can use logstash to process Liberty log output to produce more robust events. How you link logstash and Liberty together will depend on how and where Liberty is running. As a bare minimum useful for testing filters, you can try something like the following:
1$ wlp/bin/server run | logstash -f /path/to/logstash.conf You can use the -e command line option to define your filters inline, but I&amp;rsquo;m starting with the configuration file up front because I&amp;rsquo;ll spend the rest of the post adding things to it.
Changing the output / making sure it works I&amp;rsquo;ll start with the log-processing equivalent of &amp;ldquo;Hello World&amp;rdquo;. Edit your logstash.conf file to contain:
input { stdin { } } output { stdout { } } You get back pretty much exactly what you had before (with a leading message about logstash startup being complete and additional leading logstash timestamps):
1$ wlp/bin/server run | logstash -f logstash.conf 2Logstash startup completed 32015-08-26T22:23:04.587Z ec2db0f13b8f Launching defaultServer (WebSphere Application Server 8.5.5.6/wlp-1.0.9.cl50620150610-1749) on OpenJDK 64-Bit Server VM, version 1.8.0_45-internal-b14 (en) 42015-08-26T22:23:04.588Z ec2db0f13b8f [8/26/15 22:22:45:918 UTC] 00000001 id= com.ibm.ws.kernel.launch.internal.FrameworkManager A CWWKE0001I: The server defaultServer has been launched. This does increase the amount of time it takes before we can see that the server has started properly, as the messages piped through logstash get delayed a bit while logstash starts itself.
Debugging Given we&amp;rsquo;re going to start doing crazy things, we&amp;rsquo;ll want to be able to see how we changed what logstash stores for each entry. We&amp;rsquo;ll use the rubydebug codec to do this:
output { stdout { codec =&amp;gt; rubydebug } ... } Once we add that, those first few lines now look like this (please do scroll right):
Handle multiple lines We&amp;rsquo;re going to start adding filters in the next few sections. The first we will add is for multi-line output.
input { ... } filter { # Combine lines that do not start with &amp;quot;[&amp;quot; or # contain &amp;quot;WebSphere Application Server&amp;quot; with the previous message multiline { pattern =&amp;gt; &amp;quot;(^[)|(WebSphere Application Server)&amp;quot; negate =&amp;gt; true what =&amp;gt; &amp;quot;previous&amp;quot; } ## MORE HERE. } output { ... } Note first that the pattern is negated; we&amp;rsquo;re asserting that any line that does not match the pattern is a continuation, and should be lumped together with the previous line.
Liberty log entries (and even wrapped System.out or System.err output) all start with a bracketed timestamp that looks something like, [8/26/15 22:22:45:918 UTC]. But, remember that first line of Liberty trace? &amp;ldquo;Launching defaultServer (WebSphere Application Server 8.5.5.6/wlp-1.0.9.cl50620150610-1749)&amp;rdquo;. Since this is the very first line of output, we have to account for it as a standalone line (go ahead and take it out if you don&amp;rsquo;t believe me&amp;hellip; ).
Without logstash (just using raw Liberty), you might see the following output if you use an include to reconfigure your httpEndpoint. Note that the Liberty log timestamp is only on the first line, as this is a multi-line entry that is (further) not a stack trace:</description></item><item><title>Don't Wait! Play with Async EE7 instead</title><link>/2015/08/21/don-t-wait-build-responsive-applications-with-java-ee-7-instead.html</link><pubDate>Fri, 21 Aug 2015 00:00:00 +0000</pubDate><guid>/2015/08/21/don-t-wait-build-responsive-applications-with-java-ee-7-instead.html</guid><description> Note: Originally posted on IBM DeveloperWorks. Some of this content is old, but the gist is still useful.
Java EE 7 introduced additional support for asynchronous request processing over and above the asynchronous servlets and EJBs that were provided in Java EE 6. Java EE 7 includes support for WebSockets, non-blocking I/O in Servlet 3.1, asynchronous processing in JAX-RS 2.0, and Concurrency Utilities for container-supported multi-threading. All of these capabilities have a role to play in making new flavors of applications and application architectures more responsive and efficient.
Responsive applications to improve the user experience Consider single page applications (SPA). JavaScript is loaded and run on the client-side as a long-running process (for as long as that browser window/tab, or mobile phone application is active). If you’ve used Gmail or Facebook, or have done some shopping at Amazon, you know what an SPA looks and feels like. When working with an SPA, the user no longer experiences a full page refresh: event-driven, partial page updates are the norm in this environment.
An SPA client generates multiple separate requests to the back-end server to populate different areas of the page. From a user experience point of view, this is great! No blank pages of doom! No tapping of fingers waiting for something to load before you give up and go do something else. Things are a little different when looking at what happens to the supporting infrastructure.
Handling connections to responsive applications If the application happens to have frequent updates with small payloads, connection management can become a real problem. The metadata for the HTTP request alone can dwarf the size of the payload it needs to carry, never mind the cost of establishing connections, dealing with proxies, or performing SSL handshakes. There are some connection management tricks that can be played to reduce the overhead, but there is a trade-off in complexity, especially if you want data to be able to flow both ways.
Using WebSockets upgrades an established HTTP connection into a persistent connection that allows for efficient two-way communication between the client and the server. This eliminates the overhead and complexity of managing multiple connections to achieve the same end. Chat applications everywhere, rejoice!
What happens if the application is running on an under-powered client, or on a client on a slow network? Non-blocking I/O support introduced in Servlet 3.1 allows the server-side application to define handlers that can be used to read or write the next chunk of data when the opposite end of the connection is finally ready to provide or receive it. In the meanwhile, the server-side application can happily be handling other requests.
Asynchronous support in JAX-RS 2.0 What I think will get the most attention and use is async support in JAX-RS 2.0, mostly because HTTP/REST is such a commonly used protocol. Using the @Suspended annotation allows the association between the inbound connection and the request-processing thread to be broken (suspended). That association can then be resumed later to send the response. When combined with either Asynchronous EJBs (of the lite variety) or Concurrency Utilities (to help with context propagation), there is a lot more flexibility with how work is processed on the server-side.
I put together a collection of samples to show what these technologies look like in use. They are small and simple and have their origins in my IBM Interconnect session from February 2015. They are progressive in nature, beginning usually with the pre-Java EE 7 status quo, and then stepping through using the technology and, in some cases, showing some alternate usage patterns.
I hope you find them useful, feedback is welcome!
WebSockets: WASdev/sample.async.websockets Servlet Non-blocking I/O: WASdev/sample.async.servletnio Async support in JAX-RS 2.0: WASdev/sample.async.jaxrs</description></item><item><title>Building portable, 12-factor microservices with WAS Liberty and Bluemix</title><link>/2015/08/12/building-portable-12-factor-microservices-with-was-liberty-and-bluemix.html</link><pubDate>Wed, 12 Aug 2015 00:00:00 +0000</pubDate><guid>/2015/08/12/building-portable-12-factor-microservices-with-was-liberty-and-bluemix.html</guid><description> Note: Originally posted on IBM DeveloperWorks. Some of this content is old, but the gist is still useful.
The microservices approach for building (or decomposing) complex applications has received a lot of attention because it can bring so many benefits. Small teams work independently on different parts of the application, moving their standalone piece from development to production at their own pace via a devOps/self-service deployment infrastructure.
The key to this application structure is what each piece, each service, does. The phrase “high cohesion and low coupling” strongly applies: each service should do/own/manage whatever is necessary to provide a useful function. Services in this model are not necessarily small, but they are self-contained and can be updated independently.
Microservices applications are built and oriented around decoupled, independent services. This approach is a specific variant of SOA, one that eschews mediating ESBs in favor of smart endpoints that make their own decisions about how to interact with target services.
These independent services are managed in a significantly different way than traditional enterprise applications. Services are made available via collections of individual, transient service instances. The number of instances will vary based on load.
Service upgrades are performed via blue/green (or red/black) deployments: new versions are deployed side-by-side with old versions, with old versions gradually being removed as clients of the service begin using the new version. This is a rip-and-replace upgrade process, where deployed services are replaced with a newer version rather than migrated.
Given all of this, are there best practices for creating microservices? The Twelve-factor application methodology is one frequently referenced approach. It defines factors that services should follow to build portable, resilient applications for cloud environments (SaaS). To quote, 12-factor applications:
Use declarative formats for setup automation, to minimize time and cost for new developers joining the project; Have a clean contract with the underlying operating system, offering maximum portability between execution environments; Are suitable for deployment on modern cloud platforms, obviating the need for servers and systems administration; Minimize divergence between development and production, enabling continuous deployment for maximum agility; And can scale up without significant changes to tooling, architecture, or development practices.
All of the 12 factors can be satisfied by a Java EE 7 application running on WAS Liberty: some factors are specific to how the application is built, some are based on how the supporting server is configured, and some are aspects of the surrounding environment.
If you want to know more about microservices, 12-factor apps, or Java EE 7, we have you covered. Check out the following:
Microservices Architecture (Martin Fowler, martinfowler.com) Microservices: From Theory to Practice. Creating Applications in Bluemix Using the Microservices Approach (IBM Redbook) The 12-factor application (Adam Wiggins, 12factor.net)</description></item><item><title>Interview with Alex Blewitt: OSGi and Liberty</title><link>/2014/10/24/interview-with-alex-blewitt-osgi-and-liberty.html</link><pubDate>Fri, 24 Oct 2014 00:00:00 +0000</pubDate><guid>/2014/10/24/interview-with-alex-blewitt-osgi-and-liberty.html</guid><description>&lt;p>I &lt;a href="https://www.infoq.com/interviews/erin-schnabel-liberty-profile/">sat down with Alex Blewitt&lt;/a> while at OSGi DevCon to talk about Liberty and how it uses OSGi to do ridiculous things.&lt;/p>
&lt;p>The interview has just been published to InfoQ.&lt;/p></description></item><item><title>OSGi DevCon 2014: Building a right-sized, do-anything runtime using OSGi technologies</title><link>/2014/06/13/osgi-devcon-building-a-right-sized-do-anything-runtime-using-osgi-technologies.html</link><pubDate>Fri, 13 Jun 2014 00:00:00 +0000</pubDate><guid>/2014/06/13/osgi-devcon-building-a-right-sized-do-anything-runtime-using-osgi-technologies.html</guid><description>&lt;p>This was a fun conference. In NYC, co-located with QCon and filled with lots of great people. Explaining the crazy things Liberty does is also a blast.&lt;/p></description></item><item><title>IBM Impact 2014: WebSockets and Liberty Deployment Topologies</title><link>/2014/05/03/ibm-impact-2014-websockets-and-liberty-deployment-topologies.html</link><pubDate>Sat, 03 May 2014 00:00:00 +0000</pubDate><guid>/2014/05/03/ibm-impact-2014-websockets-and-liberty-deployment-topologies.html</guid><description>&lt;p>This was also my first talk in a long time, given in a big ballroom. Nothing like jumping right in.&lt;/p>
&lt;ol>
&lt;li>WebSockets for Java EE&lt;/li>
&lt;li>Liberty Series: WebSphere Liberty Profile Deployment Topologies (with Chris Vignola)&lt;/li>
&lt;/ol></description></item><item><title>NY WebSphere Users Group: WebSphere Liberty</title><link>/2014/04/10/ny-websphere-users-group-websphere-liberty-core.html</link><pubDate>Thu, 10 Apr 2014 00:00:00 +0000</pubDate><guid>/2014/04/10/ny-websphere-users-group-websphere-liberty-core.html</guid><description>Met with WebSphere User Group to talk about all things Liberty.</description></item></channel></rss>