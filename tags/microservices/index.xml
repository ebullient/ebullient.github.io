<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>microservices on ebullient·works</title><link>/tags/microservices.html</link><description>Recent content in microservices on ebullient·works</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 05 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/microservices/index.xml" rel="self" type="application/rss+xml"/><item><title>The Mechanics of Metrics, at DevNexus</title><link>/2021/03/05/DevNexus-2021-mechanics-of-metrics.html</link><pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate><guid>/2021/03/05/DevNexus-2021-mechanics-of-metrics.html</guid><description>A reframing of the metrics talk, with a much more detailed look at how emitted metrics are aggregated by PromQL / Grafana dashboards.
I quite like this one, to be honest.</description></item><item><title>Metrics for the win! at J4K Conference</title><link>/2020/11/12/metrics-for-the-win-at-j4k.html</link><pubDate>Thu, 12 Nov 2020 00:00:00 +0000</pubDate><guid>/2020/11/12/metrics-for-the-win-at-j4k.html</guid><description>A longer form of Metrics for the Win! recorded for J4K, which occurred in October of 2020.</description></item><item><title>D&amp;D and Metrics: an unexpected journey</title><link>/2020/11/09/an-unexpected-journey-with-metrics.html</link><pubDate>Mon, 09 Nov 2020 00:00:00 +0000</pubDate><guid>/2020/11/09/an-unexpected-journey-with-metrics.html</guid><description>I was asked, based solely on the abstract for my 2020 DevNexus talk, if I would be interested in writing an article on the topic. I agreed. The resulting article was published in Germina, in the September 2020 issue of Java Magazin, with &amp;ldquo;Dungeons and Dragons&amp;rdquo; as the title. I have a lovely hard-copy in my office.
The English version has also now been published at JaxEnter, &amp;ldquo;Monsters in combat: exploring application metrics with D&amp;amp;D&amp;rdquo;.
I hope you enjoy it.</description></item><item><title>Metrics for the win! at JConf</title><link>/2020/10/12/metrics-for-the-win-at-jconf.html</link><pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate><guid>/2020/10/12/metrics-for-the-win-at-jconf.html</guid><description>A fully online recorded talk, sliding in at just 30 minutes, for JConf in the fall of 2020.</description></item><item><title>Monsters and Metrics at SpringOne 2019</title><link>/2019/10/23/springone-monsters-metrics.html</link><pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate><guid>/2019/10/23/springone-monsters-metrics.html</guid><description>Two things collided in my brain this year ahead of SpringOne: Preparing a new talk from scratch covering the Micrometer (and the related Spring implementation), and learning everything I needed to know to be a Dungeon Master for my 10-year-old son and his friends.
Thanks to a brilliant suggestion from a friend, these two things collided in the talk, too. Which lightened the mental load (or at least reduced the amount of full stack swapping going on).
Github repository: ebullient/monster-combat with Spring Boot 2, WebFlux, and Micrometer</description></item><item><title>Cloud-Native Security for Java: Code @ Think</title><link>/2019/02/16/Code-Think-CloudNative-Security.html</link><pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate><guid>/2019/02/16/Code-Think-CloudNative-Security.html</guid><description>&lt;p>Billy and I put together a tidy little talk about Cloud-Native
Security for Java applications to give at &amp;ldquo;Code @ Think&amp;rdquo; during
the annual IBM Think Conference.&lt;/p></description></item><item><title>What is a Cloud Native application, anyway?</title><link>/2018/03/10/IndexConf-CloudNative.html</link><pubDate>Sat, 10 Mar 2018 00:00:00 +0000</pubDate><guid>/2018/03/10/IndexConf-CloudNative.html</guid><description>&lt;p>I gave a few talks at &lt;strong>Index&lt;/strong> Developer Conference in San Francisco:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>A Workshop! Game-On Text Adventure re-presented in lab form, with some lessons learned along the way.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Testing Cloud Native Applications&lt;/p>
&lt;/li>
&lt;li>
&lt;p>What is a Cloud Native Application, anyway? My first attempt at talking about what is going on with Cloud Native applications these days.&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>Game On! Explore microservices with a text-based adventure</title><link>/2016/05/16/game-on-explore-microservices-with-a-text-based-adventure.html</link><pubDate>Mon, 16 May 2016 00:00:00 +0000</pubDate><guid>/2016/05/16/game-on-explore-microservices-with-a-text-based-adventure.html</guid><description>Microservices: the buzz is everywhere. Given the breadth of technologies related to the term, it can be difficult to get a full picture of what a Microservices architecture should look like, or to understand why it is said that microservices architectures both remove and introduce complexity at the same time. Game On! is a throwback text-based adventure built to help you explore microservices concepts.
Continue with post on IBM developerWorks</description></item><item><title>Swagger-first API design</title><link>/2016/01/27/swagger-first-api-design.html</link><pubDate>Wed, 27 Jan 2016 00:00:00 +0000</pubDate><guid>/2016/01/27/swagger-first-api-design.html</guid><description>&lt;p>I've been working for the past few months on building Game On! a microservices-based application that is intended to show both what a microservices architecture looks like, and to make it easy for people to play with such a system without having to start from the ground up themselves.&lt;/p>
&lt;p>We started with a best-guess set of services, and over time, it became pretty apparent that our first pass at a map building service (the Concierge) was both misleading in purpose and insufficient in function. It did serve its purpose, filling in for service discovery in a way, but we were growing beyond what the service could do. &lt;/p></description></item><item><title>Shell prompt crazy for Git Submodules</title><link>/2015/12/16/shell-prompt-crazy-for-git-submodules.html</link><pubDate>Wed, 16 Dec 2015 00:00:00 +0000</pubDate><guid>/2015/12/16/shell-prompt-crazy-for-git-submodules.html</guid><description>I've run a somewhat odd little script to generate my command prompt for years now, sets some colors, adds some indicators of what kind of shell I'm in (sudo or tmux/screen or ssh or.. ).
Given I now have to work with git and submodules, I've revised that to include information provided about git generated by this script: https://github.com/git/git/blob/master/contrib/completion/git-prompt.sh
The difference is worth it, in understanding at a glance what is going on without typing git status or variant every two seconds. ;)
I've also been using some very useful aliases to make working with submodules sane, as documented here: Game On! Advanced Adventures / Git Submodules</description></item><item><title>Microservices and WAS Liberty</title><link>/2015/12/11/microservices-and-was-liberty.html</link><pubDate>Fri, 11 Dec 2015 00:00:00 +0000</pubDate><guid>/2015/12/11/microservices-and-was-liberty.html</guid><description>Home to Microservices and WAS Liberty resources, which provide background information, getting started guidance, best practices, and methodologies.
Continue with post on IBM developerWorks</description></item><item><title>Trying to tell the human story...</title><link>/2015/12/08/trying-to-tell-the-human-story.html</link><pubDate>Tue, 08 Dec 2015 00:00:00 +0000</pubDate><guid>/2015/12/08/trying-to-tell-the-human-story.html</guid><description>Writing is always hard. Writing technical stuff is hard. Writing technical stuff that doesn't sound like it is a regurgitated text book&amp;#8230; sigh
I've been leading a team working on or with Microservices at IBM (lots of people everywhere are doing things with microservices, this should come as no surprise). We've been specifically looking at how to modernize an existing Java EE application. There are articles about this, but they are all formal, and (to me) preachy.
We're doing the experiment live, so to speak. Taking the crufty Plants By WebSphere application and pulling it apart bit by bit. Our aim is to make sure you have a functional application at all times, and to frankly just share our thoughts as we try it. Let us know what you think.
Blog posts (there will be more): Rules of Engagement Getting started
Articles (longer lived, some procedure): Decomposition Choosing a candidate Breaking the candidate out into its own microservice</description></item><item><title>Secure Microservices: API Keys, Access Tokens, and Signed JWTs</title><link>/2015/12/04/secure-microservices-api-keys-access-tokens-and-signed-jwts.html</link><pubDate>Fri, 04 Dec 2015 00:00:00 +0000</pubDate><guid>/2015/12/04/secure-microservices-api-keys-access-tokens-and-signed-jwts.html</guid><description>Some samples demonstrating how to secure your microservices using API keys, access tokens, and JSON Web Tokens (JWTs).
Continue with post on IBM developerWorks</description></item><item><title>Using Grok filters to parse Liberty Logs</title><link>/2015/09/02/logstash-and-liberty-optimizing-data-collection-for-the-cloud.html</link><pubDate>Wed, 02 Sep 2015 00:00:00 +0000</pubDate><guid>/2015/09/02/logstash-and-liberty-optimizing-data-collection-for-the-cloud.html</guid><description>Note: Originally posted on Continue with post on IBMDeveloperWorks. Some of this content is old, but the gist is still useful.
Microservice architectures are highly distributed, with services provided by individual processes that are scaled independently. Understanding and maintaining overall system health becomes increasingly difficult as the system grows; it becomes impractical to look at services instance-by-instance. Monitoring systems like nagios help, but what happens when things go wrong? It is not always possible (much less easy) to ssh into any given system. In some environments the filesystem used by any given instance is transient; when the process stops, the filesystem is cleaned up, including all the logs!
The ELK stack (Elasticsearch, Logstash, and Kibana) is a commonly used system for gathering data (both logs and metrics), and allowing that data to be aggregated, analyzed, visualized, and searched in useful ways.
In this post, I'll focus on getting the most out of WAS Liberty logs using logstash. This isn't the only way: the IBM WebSphere Liberty buildpack in Bluemix, for example, uses loggregator (Cloud Foundry) rather than logstash. But I do hope that this gives you some ideas for how to make the logging capabilities in WAS Liberty work for your environment.
Getting useful information to system streams When operating on its own, WAS Liberty produces a few different log files by default:
&amp;ldquo;console&amp;rdquo; output is lightly formatted and contains no timestamps. Failure/error messages and System.err are routed to STDERR, while other important messages and System.out, are routed to STDOUT. When run in the background via server start, both streams are collected into a console.log file. messages.log also collects System out, System err, as well as a larger subset of messages (including INFO). trace.log only appears if detailed trace is enabled. It includes output from all enabled log sources, including System.out and System.err. Having log messages go directly to STDOUT and/or STDERR is a good environment-agnostic practice for microservices (and is also one of the 12-factors). It is a pretty simple change to get formatted Liberty logs writing to STDOUT. To ensure we don't miss any messages from server bootstrap and startup, we'll do this via a bootstrap.properties file that contains:
# Write WLP logs to stdout directly com.ibm.ws.logging.trace.file.name=stdout As you might infer, this re-routes what would go to trace.log to STDOUT. Before this change, STDOUT when running Liberty looks something like this:
$ wlp/bin/server run Launching defaultServer (WebSphere Application Server 8.5.5.6/wlp-1.0.9.cl50620150610-1749) on Java HotSpot(TM) 64-Bit Server VM, version 1.7.0_72-b14 (en_US) [AUDIT ] CWWKE0001I: The server defaultServer has been launched. Afterwards, it looks more like (notice the leading timestamp and fixed fields):
$ wlp/bin/server run Launching defaultServer (WebSphere Application Server 8.5.5.6/wlp-1.0.9.cl50620150610-1749) on Java HotSpot(TM) 64-Bit Server VM, version 1.7.0_72-b14 (en_US) [8/25/15 12:40:44:479 EDT] 00000001 id= com.ibm.ws.kernel.launch.internal.FrameworkManager A CWWKE0001I: The server defaultServer has been launched. In some cases, this might be enough. If you're running Liberty in the foreground in a Docker container, Liberty's formatted log entries would now be spilling out as the Docker container's STDOUT. If the hosting environment does post-processing on that output, you may have nothing left to do.
Using logstash to post-process logs However, we can use logstash to process Liberty log output to produce more robust events. How you link logstash and Liberty together will depend on how and where Liberty is running. As a bare minimum useful for testing filters, you can try something like the following:
$ wlp/bin/server run | logstash -f /path/to/logstash.conf You can use the -e command line option to define your filters inline, but I'm starting with the configuration file up front because I'll spend the rest of the post adding things to it.
Changing the output / making sure it works I'll start with the log-processing equivalent of &amp;ldquo;Hello World&amp;rdquo;. Edit your logstash.conf file to contain:
input { stdin { } } output { stdout { } } You get back pretty much exactly what you had before (with a leading message about logstash startup being complete and additional leading logstash timestamps):
$ wlp/bin/server run | logstash -f logstash.conf Logstash startup completed 2015-08-26T22:23:04.587Z ec2db0f13b8f Launching defaultServer (WebSphere Application Server 8.5.5.6/wlp-1.0.9.cl50620150610-1749) on OpenJDK 64-Bit Server VM, version 1.8.0_45-internal-b14 (en) 2015-08-26T22:23:04.588Z ec2db0f13b8f [8/26/15 22:22:45:918 UTC] 00000001 id= com.ibm.ws.kernel.launch.internal.FrameworkManager A CWWKE0001I: The server defaultServer has been launched. This does increase the amount of time it takes before we can see that the server has started properly, as the messages piped through logstash get delayed a bit while logstash starts itself.
Debugging Given we're going to start doing crazy things, we'll want to be able to see how we changed what logstash stores for each entry. We'll use the rubydebug codec to do this:
output { stdout { codec =&amp;gt; rubydebug } ... } Once we add that, those first few lines now look like this (please do scroll right):
Handle multiple lines We're going to start adding filters in the next few sections. The first we will add is for multi-line output.
input { ... } filter { # Combine lines that do not start with &amp;quot;[&amp;quot; or # contain &amp;quot;WebSphere Application Server&amp;quot; with the previous message multiline { pattern =&amp;gt; &amp;quot;(^[)|(WebSphere Application Server)&amp;quot; negate =&amp;gt; true what =&amp;gt; &amp;quot;previous&amp;quot; } ## MORE HERE. } output { ... } Note first that the pattern is negated; we're asserting that any line that does not match the pattern is a continuation, and should be lumped together with the previous line.
Liberty log entries (and even wrapped System.out or System.err output) all start with a bracketed timestamp that looks something like, [8/26/15 22:22:45:918 UTC]. But, remember that first line of Liberty trace? &amp;ldquo;Launching defaultServer (WebSphere Application Server 8.5.5.6/wlp-1.0.9.cl50620150610-1749)&amp;quot;. Since this is the very first line of output, we have to account for it as a standalone line (go ahead and take it out if you don't believe me&amp;hellip; ).
Without logstash (just using raw Liberty), you might see the following output if you use an include to reconfigure your httpEndpoint. Note that the Liberty log timestamp is only on the first line, as this is a multi-line entry that is (further) not a stack trace:</description></item><item><title>Building portable, 12-factor microservices with WAS Liberty and Bluemix</title><link>/2015/08/12/building-portable-12-factor-microservices-with-was-liberty-and-bluemix.html</link><pubDate>Wed, 12 Aug 2015 00:00:00 +0000</pubDate><guid>/2015/08/12/building-portable-12-factor-microservices-with-was-liberty-and-bluemix.html</guid><description>An overview of 12-factor applications, and how a 12-factor application can be built using WAS Liberty and Bluemix.
Continue with post on IBM DeveloperWorks</description></item></channel></rss>